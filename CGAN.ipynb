{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN预测落点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import time\n",
    "from torchvision import utils\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 坐标系变换\n",
    "def transform_coordinates(df):\n",
    "    df['tMouse_X'] = df['tMouse_X'] - (df['RectLeft'] + df['TargetWidth'] / 2)\n",
    "    df['Mouse_Y'] = -(df['Mouse_Y'] - (df['RectTop'] + df['TargetWidth'] / 2))\n",
    "\n",
    "    angle_rad = np.deg2rad(-df['DirectionAngle'])\n",
    "    tmpX = df['tMouse_X'] * np.cos(angle_rad) - df['Mouse_Y'] * np.sin(angle_rad)\n",
    "    tmpY = df['tMouse_X'] * np.sin(angle_rad) + df['Mouse_Y'] * np.cos(angle_rad)\n",
    "    \n",
    "    df['tMouse_X'] = tmpX\n",
    "    df['Mouse_Y'] = tmpY\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 去离群值\n",
    "def clear_iso(df):\n",
    "    \n",
    "    mean_y = df['Mouse_Y'].mean()\n",
    "    std_y = df['Mouse_Y'].std()\n",
    "    mean_x = df['tMouse_X'].mean()\n",
    "    std_x = df['tMouse_X'].std()\n",
    "    df = df[(df['tMouse_X'] > mean_y - 3 * std_y) & (df['tMouse_X'] < mean_y + 3 * std_y)]\n",
    "    df = df[(df['Mouse_Y'] > mean_x - 3 * std_x) & (df['Mouse_Y'] < mean_x + 3 * std_x)]\n",
    "    return df\n",
    "\n",
    "# 将落点平移到第一象限\n",
    "def translation(df):\n",
    "    df['tMouse_X'] -= df['tMouse_X'].min()\n",
    "    df['Mouse_Y'] -= df['Mouse_Y'].min()\n",
    "    return df\n",
    "\n",
    "# 将落点居中\n",
    "def centering(df, target_center_X, target_center_Y):\n",
    "    current_center_X = df['tMouse_X'].mean()\n",
    "    current_center_Y = df['Mouse_Y'].mean()\n",
    "    offset_X = target_center_X - current_center_X\n",
    "    offset_Y = target_center_Y - current_center_Y\n",
    "    df['tMouse_X'] += offset_X \n",
    "    df['Mouse_Y'] += offset_Y\n",
    "    return df\n",
    "\n",
    "# 获取采样后图形，目前为np.array格式\n",
    "def data_augmentation(df, width, velocity, repetitions, fraction):\n",
    "    filterdata = df[(df['TargetWidth'] == width) & (df['Velocity'] == velocity)]\n",
    "    filterdata = clear_iso(filterdata)\n",
    "    images = []\n",
    "    for _ in range(repetitions):\n",
    "        sampledata = filterdata.sample(frac=fraction, replace=False)\n",
    "        sampledata = translation(sampledata)\n",
    "        sampledata = centering(sampledata, 128, 128)\n",
    "        image = np.zeros((256, 256), dtype=float)\n",
    "        for _, row in sampledata.iterrows():\n",
    "            x, y = int(row['tMouse_X']), int(row['Mouse_Y'])\\\n",
    "            # 暂时先不考虑点重合的问题\n",
    "            image[y][x] += 1\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "# 获取目标图像\n",
    "def get_target(width, velocity):\n",
    "    image = np.zeros((256, 256), dtype=float)\n",
    "    center_y, center_x = 128, 128\n",
    "    for y in range(256):\n",
    "        for x in range(256):\n",
    "            # 计算当前点到圆心的距离\n",
    "            distance = np.sqrt((center_x - x) ** 2 + (center_y - y) ** 2)\n",
    "            \n",
    "            # 如果距离接近半径width（可以设定一个小的容忍范围，比如±1）\n",
    "            if np.abs(distance - width) <= 1:\n",
    "                image[y][x]= velocity\n",
    "    return image\n",
    "\n",
    "def visualize_samples(dataset, widths, velocities):\n",
    "    fig, axs = plt.subplots(len(widths) * len(velocities), 2, figsize=(10, 5 * len(widths) * len(velocities)))\n",
    "\n",
    "    for i, (width, velocity) in enumerate(itertools.product(widths, velocities)):\n",
    "        for j in range(len(dataset)):\n",
    "            image, condition = dataset[j]\n",
    "            current_condition = get_target(width, velocity)\n",
    "            if np.array_equal(condition.squeeze().numpy(), current_condition):\n",
    "                axs[i, 0].imshow(image.squeeze().numpy(), cmap='gray')  # 显示图像\n",
    "                axs[i, 0].set_title(f\"Image - Width: {width}, Velocity: {velocity}\")\n",
    "                axs[i, 0].axis('off')\n",
    "\n",
    "                axs[i, 1].imshow(condition.squeeze().numpy(), cmap='gray')  # 显示条件图\n",
    "                axs[i, 1].set_title(f\"Condition - Width: {width}, Velocity: {velocity}\")\n",
    "                axs[i, 1].axis('off')\n",
    "                break\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/total_mouse.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data = transform_coordinates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointDataset(Dataset):\n",
    "    def __init__(self, data, widths, velocities, repetition, fraction):\n",
    "        self.data_pairs = []\n",
    "\n",
    "        for width, velocity in itertools.product(widths, velocities):\n",
    "            dataset = data_augmentation(data, width, velocity, repetition, fraction)\n",
    "            condition = get_target(width, velocity)\n",
    "\n",
    "            dataset = [torch.tensor(img, dtype=torch.float32).unsqueeze(0) for img in dataset]\n",
    "            condition = torch.tensor(condition, dtype=torch.float32).unsqueeze(0)\n",
    "            for img in dataset:\n",
    "                self.data_pairs.append((img, condition))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_pairs[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocitys = [64, 128, 192]\n",
    "# widths = [16, 32, 64, 96]\n",
    "# dataset = PointDataset(data, widths, velocitys, 10, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(dataset, batch_size=20, shuffle=False)\n",
    "# epoch = 1\n",
    "# for i in range(epoch):\n",
    "#     for j, (images, conditions) in enumerate(dataloader):\n",
    "#         print(f\"Batch {j + 1}:\")\n",
    "#         print(f\"  Images Shape: {images.shape}\")     \n",
    "#         print(f\"  Conditions Shape: {conditions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_samples(dataset, widths, velocitys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建CGAN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=100,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=8,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=64,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "                     \n",
    "        )\n",
    "        self.conditions = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=4,\n",
    "                      stride=4,\n",
    "                      padding=0,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=4,\n",
    "                      stride=4,\n",
    "                      padding=0,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),        \n",
    "        )\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=4,\n",
    "                               stride=4,\n",
    "                               padding=0,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=256,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=128,\n",
    "                               out_channels=1,\n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        image = self.image(noise)\n",
    "        labels = self.conditions(labels)\n",
    "        x = torch.cat((image, labels), 1)\n",
    "        x  = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=128,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=256,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=512,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=0,\n",
    "                      bias=False\n",
    "                      ),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        d_in = torch.cat((img, labels), 1)  # 将图像和标签拼接在一起作为输入\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr_D = 2e-4\n",
    "lr_G = 2e-4\n",
    "seed = 0\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "fixed_noise = torch.randn(1, noise_dim, 1, 1).to(device)\n",
    "condition = get_target(32, 64)\n",
    "condition = torch.tensor(condition, dtype=torch.float32)\n",
    "fixed_condition = condition.unsqueeze(0).unsqueeze(0).to(device)  # 先加批次维度，再加通道维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固定种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12824dfae70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device) \n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "optimazer_G = torch.optim.Adam(generator.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "optimazer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "\n",
    "loss_tep = 10\n",
    "\n",
    "velocitys = [64, 128, 192]\n",
    "widths = [16, 32, 64, 96]\n",
    "dataset = PointDataset(data, widths, velocitys, 300, 0.8)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "img_list = []\n",
    "\n",
    "print(\"Start Training\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 记录开始时间\n",
    "    beg_time = time.time()\n",
    "    for i, (real_image, condition) in enumerate(dataloader):\n",
    "        real_image = real_image.to(device)\n",
    "        condition = condition.to(device)\n",
    "        b_size = real_image.size(0)\n",
    "\n",
    "        # 训练鉴别器\n",
    "        discriminator.zero_grad()\n",
    "        output = discriminator(real_image, condition).view(-1, 1)\n",
    "        d_loss_real = loss_function(output, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        noise = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n",
    "        fake_image = generator(noise, condition)\n",
    "        output = discriminator(fake_image.detach(), condition).view(-1, 1)\n",
    "        d_loss_fake = loss_function(output, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimazer_D.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        generator.zero_grad()\n",
    "        output = discriminator(fake_image, condition).view(-1, 1)\n",
    "        g_loss = loss_function(output, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimazer_G.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_time = round((end_time - beg_time), 2)\n",
    "\n",
    "        print(\n",
    "            f'Epoch: [{epoch+1:0>{len(str(num_epochs))}}/{num_epochs}]',\n",
    "            f'Step: [{i+1:0>{len(str(len(dataloader)))}}/{len(dataloader)}]',\n",
    "            f'Loss-D: {d_loss.item():.4f}',\n",
    "            f'Loss-G: {g_loss.item():.4f}',\n",
    "            f'Time: {run_time}s',\n",
    "            end='\\r'\n",
    "        )\n",
    "\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        if g_loss < loss_tep:\n",
    "            torch.save(generator.state_dict(), f'./models_CGAN/generator_{epoch}.pt')\n",
    "            loss_tep = g_loss\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         fake_images = generator(fixed_noise, fixed_condition).detach().cpu()\n",
    "        #     img_list.append(utils.make_grid(fake_images, nrow=10))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看损失变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G Loss\")\n",
    "plt.plot(D_losses, label=\"D Loss\")\n",
    "plt.axhline(y=0, label=\"0\", c='g')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 1, 1])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_condition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = Generator()\n",
    "test_generator.load_state_dict(torch.load('./models_CGAN/generator_7.pt', map_location=torch.device('cpu')))\n",
    "test_generator.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake = test_generator(fixed_noise.cpu(), fixed_condition.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = fake.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "threshold = 0.01\n",
    "fake_images = (fake_images > threshold).astype(np.float32)\n",
    "\n",
    "if fake_images.shape[-1] == 1:\n",
    "    fake_images = np.squeeze(fake_images, axis=-1)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(fake_images), figsize=(10, 10))\n",
    "\n",
    "for i, img in enumerate(fake_images):\n",
    "    ax = axs[i] if len(fake_images) > 1 else axs\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
